# Sentiment Analysis for Product Reviews (Amazon)

**Industry:** E-commerce  
**Goal:** Analyze customer reviews to determine sentiment (**positive / neutral / negative**) and inform product improvements.

---

## Dataset
- **Source:** Amazon Product Reviews (Kaggle) — add link: `https://www.kaggle.com/datasets/datafiniti/consumer-reviews-of-amazon-products?resource=download`
- Raw schema (subset used): `reviews.id, reviews.date, asins, brand, reviews.rating, reviews.title, reviews.text, ...`

---

## Approach

1. **Load & Preprocess**
   - Tokenize → remove punctuation & stopwords → lowercase → lemmatize
   - Training file: `data/processed/reviews_clean.csv` with columns:
     - `text` *(title + ". " + review body — used for matching back to raw)* 
     - `label` ∈ {positive, neutral, negative}  
     - `text_clean` *(cleaned string used by models)*

2. **Feature Extraction**
   - **TF-IDF** (1–2 n-grams, `max_features=50k`, `min_df=2`) for classical models
   - (Deep model tried) **embedding + BiLSTM** for comparison

3. **Models Trained**
   - Logistic Regression (baseline)
   - Linear SVM
   - Linear SVM + **RandomOverSampler**
   - **Linear SVM (Hybrid resampling)** — *chosen model*
   - BiLSTM (embeddings)

4. **Evaluation**
   - Stratified 80/20 split, untouched test set
   - Metrics: **Accuracy**, **Macro Precision/Recall/F1**
   - Confusion matrix saved to `outputs/charts/`
   - Results summary (`outputs/comparison.csv`):

     | Model            | Accuracy | Macro_Precision | Macro_Recall | Macro_F1 | Notes                          |
     |------------------|---------:|----------------:|-------------:|---------:|--------------------------------|
     | Logistic Regression | 0.672 | 0.65 | 0.51 | 0.36 | Baseline TF-IDF + LogReg |
     | SVM              | 0.923 | 0.56 | 0.53 | 0.54 | Linear SVM |
     | SVM Oversampled  | 0.926 | 0.58 | 0.55 | 0.56 | RandomOverSampler |
     | **SVM Hybrid**   | **0.935** | **0.64** | **0.55** | **0.58** | **SMOTE + undersampling (chosen)** |
     | LSTM             | 0.926 | 0.60 | 0.48 | 0.52 | BiLSTM with embeddings |

Additional artifacts:
- Confusion matrix PNGs in `outputs/charts/` (generated by training scripts).

5. **Dashboard - Export for Analysis / BI**
   - Predictions exported to `outputs/predictions.csv` for BI visualization.

---

## Inputs & Outputs

**Inputs expected**
- `data/processed/reviews_clean.csv` → columns: `text, label, text_clean`  
  *(`text` must be `reviews.title + ". " + reviews.text` so metadata can be re-attached)*
- `data/raw/amazon_reviews.csv` → raw metadata (dates, ASIN, brand, rating, title, text)

**Key outputs**
- `models/tfidf_svm_hybrid.joblib` — trained TF-IDF + LinearSVC pipeline  
- `outputs/predictions.csv` — review-level predictions + metadata (for BI)  
- `outputs/comparison.csv` — model metrics table  
- `outputs/charts/*.png` — evaluation plots (e.g., confusion matrix)

---

## Quickstart

```bash
# create & activate venv (Windows)
python -m venv .venv
.venv\Scripts\activate

# install dependencies
pip install -r requirements.txt
```

## How to Run
**Train the chosen model (SVM Hybrid)**
python src/train_svm_hybrid.py
# -> models/tfidf_svm_hybrid.joblib
# -> outputs/charts/confusion_matrix_svm_hybrid.png

**Export predictions for analysis / BI**
python src/score_reviews.py
# -> outputs/predictions.csv

## Repository Structure

```
.
├── src/
│   ├── train_baseline.py
│   ├── train_svm.py
│   ├── train_svm_undersample.py
│   ├── train_svm_resample.py
│   ├── train_svm_hybrid.py            # chosen model
│   ├── score_reviews.py               # exports outputs/predictions.csv
│   ├── utils_text.py
│   └── infer.py
├── data/
│   ├── raw/                           # (ignored) original Kaggle CSV
│   └── processed/                     # (ignored) e.g., reviews_clean.csv
├── models/                            # (ignored) saved .joblib models
├── outputs/
│   ├── predictions.csv                # review-level predictions for BI
│   ├── comparison.csv                 # model metrics summary
│   └── charts/                        # confusion matrices, etc.
├── requirements.txt
├── .gitignore
└── README.md
```

## Notes & Design Choices

Why SVM + TF-IDF? Strong baseline for short reviews; stable and fast.

Why hybrid sampling? Balances class skew; improved macro-F1 vs plain/oversample.

Reproducibility: Fixed random seeds; clean train/test split; pipeline saved as .joblib.

Limitations / Next steps: Neutral class remains challenging; consider calibrated SVM, class-weighted loss, or modern pretrained embeddings (e.g., BERT) for further gains.


